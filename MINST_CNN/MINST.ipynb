{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'y': array([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        ...,\n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 9]], dtype=uint8)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadmat('data/MINST')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400) (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data['X'].shape, data['y'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = encoder.fit_transform(data['y'])\n",
    "y_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    ones = np.ones([m, 1])\n",
    "    # Input Layer\n",
    "    a1 = np.concatenate((ones, X), axis=1)\n",
    "    # Hidden Layer\n",
    "    z2 =a1*theta1.T\n",
    "    a2 =sigmoid(z2)\n",
    "    a2 = np.concatenate((ones, a2), axis=1)\n",
    "    # Output Layer\n",
    "    z3 = a2*theta2.T\n",
    "    h = sigmoid(z3)\n",
    "    \n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    # compute the cost\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "        \n",
    "    J = J / m\n",
    "    # cost function with regularization\n",
    "    J += (float(learning_rate) / (2*m) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:],2))))\n",
    "    \n",
    "    return J\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "(5000, 400)\n",
      "\n",
      "a1\n",
      "(5000, 401)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "theta1\n",
      "(25, 401)\n",
      "\n",
      "z2\n",
      "(5000, 25)\n",
      "[[-0.44766294  0.02597435  0.48970539 ...  0.76010568  0.7225221\n",
      "   0.1789523 ]\n",
      " [-0.13707683  0.06557284  0.37509521 ...  0.78775169  0.7633191\n",
      "   0.20393546]\n",
      " [ 0.01140966 -0.24262989  0.46784691 ...  0.32154635  0.4173466\n",
      "  -0.04772692]\n",
      " ...\n",
      " [ 0.26284356  0.25281572  0.15024436 ...  0.13769077 -0.16613746\n",
      "   0.01632722]\n",
      " [ 0.07724789 -0.09249144  0.16680036 ... -0.0129061   0.40811216\n",
      "  -0.1087338 ]\n",
      " [-0.05870841  0.19572541  0.47346771 ...  0.01144183  0.33825102\n",
      "  -0.24973437]]\n",
      "\n",
      "a2\n",
      "(5000, 26)\n",
      "[[1.         0.38991657 0.50649322 ... 0.68137668 0.67316216 0.54461906]\n",
      " [1.         0.46578435 0.51638734 ... 0.68734837 0.68207391 0.5508079 ]\n",
      " [1.         0.50285238 0.43963836 ... 0.57970106 0.60284814 0.48807053]\n",
      " ...\n",
      " [1.         0.56533517 0.56286942 ... 0.53436841 0.45856091 0.50408172]\n",
      " [1.         0.51930237 0.47689361 ... 0.49677352 0.60063512 0.4728433 ]\n",
      " [1.         0.48532711 0.54877574 ... 0.50286043 0.58376561 0.43788888]]\n",
      "\n",
      "theta2\n",
      "(10, 26)\n",
      "\n",
      "z3\n",
      "(5000, 10)\n",
      "[[ 0.04231522 -0.05752432 -0.20214164 ... -0.15262246  0.15834485\n",
      "   0.10864054]\n",
      " [ 0.06530299 -0.05535179 -0.15998865 ... -0.14475084  0.14364672\n",
      "   0.09925705]\n",
      " [ 0.04873705 -0.06766174 -0.17283298 ... -0.15740968  0.16514456\n",
      "   0.09943737]\n",
      " ...\n",
      " [-0.01192973 -0.0836388  -0.149636   ... -0.19819728  0.13326178\n",
      "   0.07202219]\n",
      " [ 0.02486981 -0.08642938 -0.1341292  ... -0.16944951  0.14086107\n",
      "   0.05844222]\n",
      " [ 0.03122896 -0.05067411 -0.16406005 ... -0.19134219  0.16441565\n",
      "   0.09925671]]\n",
      "\n",
      "h\n",
      "(5000, 10)\n",
      "[[0.51057723 0.48562288 0.44963597 ... 0.46191828 0.53950371 0.52713345]\n",
      " [0.51631995 0.48616559 0.46008793 ... 0.46387534 0.53585006 0.52479391]\n",
      " [0.51218185 0.48309102 0.45689899 ... 0.46072864 0.54119256 0.52483888]\n",
      " ...\n",
      " [0.4970176  0.47910248 0.46266065 ... 0.45061225 0.53326623 0.51799777]\n",
      " [0.50621713 0.47840609 0.46651788 ... 0.4577387  0.53515715 0.5146064 ]\n",
      " [0.50780661 0.48733418 0.45907674 ... 0.45230987 0.54101157 0.52479382]]\n"
     ]
    }
   ],
   "source": [
    "# initial setup\n",
    "input_size = 400\n",
    "hidden_size = 25\n",
    "num_labels = 10\n",
    "learning_rate = 1\n",
    "# randomly initialize a parameter array of the size of the full network's parameters\n",
    "params = (np.random.random(size=hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.2\n",
    "\n",
    "m = data['X'].shape[0]\n",
    "X = np.matrix(data['X'])\n",
    "y = np.matrix(data['y'])\n",
    "# unravel the parameter array into parameter matrices for each layer\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "\n",
    "print(\"X\")\n",
    "print(X.shape)\n",
    "\n",
    "print(\"\\na1\")\n",
    "print(a1.shape)\n",
    "print(a1)\n",
    "\n",
    "print(\"\\ntheta1\")\n",
    "print(theta1.shape)\n",
    "# print(theta1)\n",
    "\n",
    "print(\"\\nz2\")\n",
    "print(z2.shape)\n",
    "print(z2)\n",
    "\n",
    "print(\"\\na2\")\n",
    "print(a2.shape)\n",
    "print(a2)\n",
    "\n",
    "print(\"\\ntheta2\")\n",
    "print(theta2.shape)\n",
    "# print(theta2)\n",
    "\n",
    "print(\"\\nz3\")\n",
    "print(z3.shape)\n",
    "print(z3)\n",
    "\n",
    "print(\"\\nh\")\n",
    "print(h.shape)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.624363089452915"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(params, input_size, hidden_size, num_labels, X, y_onehot, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = h - y\n",
    "loss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    " \n",
    "\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    #forward\n",
    "    J = 0\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    # compute the cost\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "        \n",
    "    J = J / m\n",
    "    J += (float(learning_rate) / (2*m) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:],2))))\n",
    "\n",
    "    # back\n",
    "    loss3 = h - y\n",
    "\n",
    "    gradient2 = np.matmul(np.transpose(loss3), a2)\n",
    "    gradient2 = gradient2 / m\n",
    "    gradient2[:,1:] += (float((learning_rate)) / m) * theta2[:,1:] \n",
    "\n",
    "\n",
    "    \n",
    "    loss2 = np.array(np.matmul(loss3, theta2[:,1:])) * np.array(sigmoid_gradient(z2))\n",
    "    gradient1 = np.matmul(np.transpose(loss2), a1)\n",
    "    gradient1 = gradient1 / m\n",
    "    gradient1[:,1:] += ((float(learning_rate)) / m) * theta1[:,1:]\n",
    "    \n",
    "    grad = np.array(gradient1.reshape(gradient1.shape[0] * gradient1.shape[1],))\n",
    "    grad = np.append(grad, np.array(gradient2.reshape(gradient2.shape[0] * gradient2.shape[1])))\n",
    "    #print(\"loss\", J)\n",
    "    #print(\"g:\", grad.shape)\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmin:       fun: 0.32941428067218\n",
      "     jac: array([ 1.97780041e-05, -2.46857050e-07, -1.06973442e-07, ...,\n",
      "       -2.37777099e-04, -1.46922064e-04, -2.07521785e-04])\n",
      " message: 'Max. number of function evaluations reached'\n",
      "    nfev: 250\n",
      "     nit: 22\n",
      "  status: 3\n",
      " success: False\n",
      "       x: array([ 1.32290393e+00, -1.23428525e-03, -5.34867212e-04, ...,\n",
      "        1.21070075e+00,  2.82640499e+00,  5.36469822e-01])\n",
      "accuracy = 99.33999999999999%\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "# minimize the objective function\n",
    "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size, num_labels, X, y_onehot, learning_rate), method='TNC', jac=True, options={'maxiter': 250})\n",
    "print(\"fmin: \", fmin)\n",
    "\n",
    "X = np.matrix(X)\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "y_pred = np.array(np.argmax(h, axis=1) + 1)\n",
    "\n",
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y)]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print ('accuracy = {0}%'.format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
